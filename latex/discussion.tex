\section{Discussion}
\thispagestyle{plain}  % surpress header on first page

This chapter discusses the utility and implications of the findings in the UQ. Specifically, I elaborate the broader impact that the results can potentially have. Then, I continue the methodological discussion by addressing important challenges for future research. This part of the discussion is organised along the topics measures, sampling and estimation.\\

\noindent
I analyse the uncertainty in  the effect of a 500 USD subsidy on annual tuition costs for higher education on the average years of education caused by the parametric uncertainty in the model of occupational choice by \cite{Keane.1994}. I find that the mean effect is an increase of 1.5 years in education for the whole population. \colorbox{red}{Include many references that drive home the point how benefitial this is. Also note that e.g. heckman 2016 find that college graduation is not benefitial to everybody.}
The uncertainty analysis yields the additional result that the input uncertainty accounts for a standard deviation of the QoI equals to 0.1. This is a relatively small level of variation. Knowing this uncertainty does not only improve the understanding of us economists but can also help us when we communicate our results to actors in the political arena. Revealing for example important politicians and journalists our knowledge about the low uncertainty of our results proves a high level of sophistication and reflection. A serious uncertainty analysis would increase the credibility of every economist. Therewith, our work may be more impactful.\\

\noindent
The qualitative GSA leads to three findings.
First, it confirmed the conceptual analysis that the two EEs developed have \cite{ge2017extending} two crucial disadvantages. The first is the independent EE is not independent because it deflates the impact of inputs according to their level of correlations with other parameters. Therefore, it is non a neutral measure with respect to the input parameters and both EEs cannot be independent jointly as is necessary. The second drawback is that the draws in the numerator are in sample space and those in the denominator are in unit space. The qualitative GSA based on the redesigned EEs that the thesis developed showed that it is not clear which measure is the most adequate for factor fixing. The correlated and uncorrelated sigma-normalised mean absolute EEs, $\mu_\sigma^*$ are the only factors that are not detached from the scale of the QoI variation, $\sigma_Y$. This indicates that these measures are not only able to include the effect of the variation of $X_i$ on the level of $Y$ but also on the variation of $Y$. However, I did not recommend any parameters to be fixed because the link from this measure is global sensitivity measures is not fully understood for non-linear models with interactions and correlated input parameters.\\

\noindent
Second, the radial design generates higher EEs compared to the trajectory design for all parameters. I argue that this is because the radial design generates values that can have differences as large as the whole sample space. This seems to be a disadvantage for non-linear models. It is also problematic because for example the Sobol' indices do not consider such large differences as all draws are compared with the mean. This finding is in contradiction with \cite{campolongo2007effective} who obtained better results for the radial design. Thus, it would be interesting to analyse the differences more closely.\footnote{A possible path could be the following sketch for a hybrid design in unit space: The first row contains 0.5 for each column. Each step is a random draw in [0, 0.5] Copy the changed draws to the next row as in the trajectory design and then change each column to have equiprobable interactions.}\\

\noindent
Third, the pattern in the results suggested two potential interactions between maximum likelihood estimation and sensitivity analysis for correlated input parameters. These were, assuming that the QoI is closely linked to the model observables:

Firstly, the correlated EE, $d_i^{c}$, will is smaller than the uncorrelated EE $d_i^{u}$ because parameters that have similar effects on observing $\pmb{\mathcal{D}}$ tend to be negatively correlated and those with opposite effects tend to be positively correlated. Therefore, the correlations "stabilise" the QoI against changes of specific input parameters.

Secondly, if there are not very large effect differences then parameters that tend to have a larger impact on the level of $Y$ do not tend to have a large impact on the variation in $Y$. The reason is that the estimation generates larger standard errors for parameters with a smaller impact on the observables as they influence the probability of observables less. These lines of arguments are rather speculative and it would be interesting if additional research could either confirm or contradict these hypotheses.
