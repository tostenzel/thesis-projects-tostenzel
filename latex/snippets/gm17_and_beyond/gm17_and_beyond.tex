\documentclass[a4paper,12pt]{article} 

% packages and main settings
\usepackage[left=3cm, right=2cm, top=2cm, bottom=2cm]{geometry}
\usepackage[english]{babel}    
\usepackage[utf8]{inputenc}  
\usepackage[T1]{fontenc}        
\usepackage{lmodern}            
\usepackage{microtype}          
\usepackage{amsmath}
\usepackage{amsfonts, amsthm, amssymb, graphicx, booktabs}
\usepackage{bm} %bold epsilon
\usepackage{newclude}   
\usepackage{placeins}  %surpresses floating tables
\usepackage[labelfont=bf]{caption} %Figure etc steht dann in small caps 
\usepackage[labelsep=period]{caption} % dot after figure, table caption.
\usepackage[flushleft]{threeparttable} % for notes below table
\usepackage{multirow} % for table cell merge along rows
\usepackage{graphicx} % to adjust tablesize to textwidth
\usepackage{caption}  % for centered captions
\usepackage{float} % to set of autopositioning of tables
\usepackage[bottom,hang,flushmargin]{footmisc} % forces footnotes to the bottom
\usepackage{setspace}           % Fuer 1.5 fachen Zeilenabstand  
\onehalfspacing % 1.5 cm Zeilenabstand
%Bibtex
\usepackage[round,sort&compress]{natbib}

\bibliographystyle{chicago} % chicago bib style like in AER
\usepackage[hidelinks]{hyperref} % fuer links und verweise. Cleverref ist eigentlich besser. 


% Create header. The header must be surpressed for 
% every first page per section and a solution
% for the Appendix is used in the respective subfile.
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\chead{\nouppercase{\textit{\leftmark}}}
\cfoot{\thepage}
\renewcommand{\headrulewidth}{0pt} % no vertical line

%\usepackage{lipsum}  % check if formats work

\usepackage{afterpage} %clearpage w/o pagebreak for "header bug"

% Expectation symbol
\DeclareMathOperator*{\E}{\mathbb{E}}

% thin space, limits underneath in displays
% for strike through
\DeclareMathOperator*{\argmax}{argmax}
\newcommand*{\defeq}{\stackrel{\text{def}}{=}}
\usepackage[normalem]{ulem}
% try to use strikeout in section headers and others
\DeclareRobustCommand{\hsout}[1]{\texorpdfstring{\sout{#1}}{#1}}

% for gray table row color
\usepackage[table]{xcolor}

% decimal dot alignment in table columns
\usepackage{siunitx}

% for footnotes in table
\usepackage[flushleft]{threeparttable}

% for underbar
\newcommand{\ubar}[1]{\text{\b{$#1$}}}

\usepackage{tikz}

% Setup for urls
\usepackage{url}

\defcitealias{Respy-Stenzel.2019}{\textit{respy}}
\defcitealias{Gabler.2019}{\textit{estimagic}}
\defcitealias{Stenzel.2020}{\textit{Master's Thesis Replication Repository}}
\defcitealias{NLSY79}{NLSY79}


\usepackage{tikz}
\begin{document}

\newpage % delete after section is complete

\section{\cite{ge2017extending} and beyond}
\thispagestyle{plain} % suppress header on first page
\cite{Morris.1991}

\cite{Saltelli.2008}

\cite{lemaire2013structural}

\cite{gentle2006random}

\cite{ge2017extending}

\cite{ge2014efficient}

\cite{campolongo2007effective}

\cite{Smith.2014}

\subsection{Qualitative General Sensitivity Analysis}
\noindent
Qualitative Global Sensitivity Analysis (GSA) deals with computing measures that can rank random input parameters in terms of their importance on the function output and the variability thereof. If the measures for some input parameters are negligibly small, these parameters can be fixed so that the number of random input parameters decreases for a subsequent quantitative GSA. This pre-selection step is called Factor Fixing. The quantitative GSA then aims to determine the effect size. of the random input parameters on the function output. The most common measures in quantitative GSA are the so-called Sobol' sensitivtiy indices. Equation 1 shows the first order index. It is the share of the variance in the function output induced by exclusively one single input parameter $X_i$ of the variance in the function output induced by all random input parameters $X_1, X_2, ..., X_k$.

\begin{align}
S_i = \frac{\text{Var}_i[Y|X_i ]}{\text{Var}[Y]}
\end{align}

Equation 2 show the total order index. This measure is equal to the first order index except of that it numerator includes the variance in the function output that is induced by changes in the other input parameters $X_{\sim i}$, caused by interactions with $X_i$.

\begin{align}
S_{i}^T = \frac{\E_{\sim i}[\text{Var}_{i}[Y|\bold{X_{\sim i}]]}}{\text{Var}[Y]}
\end{align}

Computing these measures requires many function evaluations, even if estimators are used that can provide some shortcuts. The more time-intense one function evaluation is, the more appealing gets the aforementioned Factor Fixing. These can provide qualitative results with less function evaluations.
The most commonly used measures in qualitative GSA is the Elementary Effect (EE), $\mu$, the absolute Elementary Effects, $\mu^*$, and the standard deviation of the Elementary Effect $\sigma$. The Elementary Effect is given by the mean of a number of function derivatives with respect to one input parameter. The "change in", or the "step of" the input parameter, denotes by $\Delta$, has not to be infinitesimally small. The derivation is denoted as
\begin{align}
d^{(j)} =  \frac{Y(\bold{X_{\sim i}^{(j)}}, X_i^{(j)} + \Delta^{(i,j)})}{\Delta^{(i,j)}},
\end{align}
where $j$ is an index for the number of parameter-specific argument observations for the function derivative.
Then, the Elementary Effect is given by

\begin{align}
\mu = \frac{1}{r} \sum_{j=1}^{r} d^{(j)}.
\end{align}
\noindent
The absolute Elementary Effects, $\mu^*$ is used to prevent observations to cancel each other out.

\begin{align}
\mu^* = \frac{1}{r} \sum_{j=1}^{r} \big| d^{(j)} \big|.
\end{align}
\noindent
In Equation 4 and 5, $r$ is the number of parameter draws with index $(j)$. Step $\Delta^{(j)}$ may or may not vary depending on the sample design that is used to draw the input parameters. These measures (together) are used to proxy the total Sobol' indices that contains the parameter-specific interactions with all other parameter in Equation(2). If they are close to 0 (,and given there are parameters with measures substantially different from 0), these respective factors' variation can be rendered as irrelevant for the variation in the function output.

\subsection{Sampling Schemes}

According to several experiments by \cite{campolongo2011screening} using common test functions, the best design is the radial design (\cite{saltelli2002making}) and the most commonly used is the trajectory design (\cite{Morris.1991}).
Both samples consist of a set of $(k + 1) \times k$-dimensional matrices. The columns represent the input parameters and each row is a complete input parameter vector.\\

\noindent
A subsample, or matrix, in radial design is generated the the following way: Draw a vector of length $2k$ from a quasi-random sequence. The first row, or parameter vector, is the first half of the sequence. Then copy the first row to the remaining $k$ rows. For each row $k'$ of the remaining 2, ..., $k+1$ rows, replace the $k'$-th element by the $k'$-th element of the second half of the vector. This generates a matrix of the following form:

$$ \bold{R} =
\begin{pmatrix}
a_1 & a_2 & ... & a_k \\
\bold{b_1} & a_2 & ... & a_k \\
a_1 & \bold{b_2} & ... & a_k \\
\vdots & \vdots & \vdots & \vdots\\

a_1 & a_2 & ... & \bold{b_k}
\end{pmatrix}
$$

\noindent
Note here, that each column consists only of the first row element, except of one row.
From this matrix, one individual EE can be obtained for each parameter $X_i \in X_1, X_2, ..., X_k$. This is achieved by using the $i+1$-th row as function argument for the minuend and the first row as subtrahend in the formula for the individual EE. Then, $\Delta^{(i,j)} = b_i^{(j)} - a_i^{(j)}$. This yields to the following re-formulation of the derivation in Equation (3).
\begin{align}
d^{(j)} =  \frac{Y(\bold{a_{\sim i}^{(j)}}, b_i^{(j)}) - Y(\bold{a})}{b_i^{(j)} - a_i^{(j)}} = \frac{Y(\bold{R_{i,*}}) -  Y(\bold{R_{1,*}})}{b_i^{(j)} - a_i^{(j)}}.
\end{align}
If the number of radial subsamples is high, the quasi-random sequence lead to a good coverage of the input space. The quasi-random sequence considered here is the Sobol' sequence. This sequence is comparably succesful in covering interval the unit hypercube but also conceptually more involved. Therefore, it's presentation is beyond the scope of this work. Since this sequence is quasi-random, the sequence has to be drawn at once for all sets of radial matrices.\\

\noindent
Next, I present the trajectory design. As we will see, it leads to a relatively representative coverage for a very small number of subsamples but leads to frequent repetitions of similar draws for higher number of draws.
In this outline, I skip the exact equations that produces a trajectory and simply present the method verbally.
There are multiple approaches to construct different forms of trajectory. Here, I focus on the version presented in \cite{Morris.1991} that yields to equiprobable elements. The first step is to decide the number $p$ of grid points in interval $[0,1]$. Then, the first row of the trajectory is composed of the lower half value of these grid points. Now, fix $\Delta = p/[2(p-1)]$. This function implies, that the lowest point in the lowest half results in the lowest point of the upper half of the grid points if $\Delta$ is added. The rest of the rows is constructed by, first, copying the upper row and, second, by adding $\Delta$ to the $k$-th element of the $k+1$-th row. The implied matrix scheme is depictet below.

$$\bold{T} =
\begin{pmatrix}
a_1 & a_2 & ... & a_k \\
\bold{b_1} & a_2 & ... & a_k \\
\bold{b_1} & \bold{b_2} & ... & a_k \\
\vdots & \vdots & \vdots & \vdots\\

\bold{b_1} & \bold{b_2} & ... & \bold{b_k}
\end{pmatrix}
$$
\\

\noindent
In contrary to the radial scheme, each $b_i$ is copied to the subsequent row. Therefore, the EEs have to be determined by comparing each row with the row above instead of with the first row.
Importantly, two random transformations are common. These are randomly switching rows and randomly interchanging the $i$-th column with the $(k-i)$-th column. The first transformation is skipped as it does not add additional coverage and because we need the stairs-shape facilitate later transformations to account for correlation between input parameters. The second transformation is adapted because it is important to also have negative $\Delta$ and because it does also sustain the stairs-shape. Yet, this implies that $\Delta$ is also column and trajectory specific. Let $f$ and $h$ be additional index parameters. The derivation formula is adapted to the trajectory design as follows\footnote{In contrary to most authors, I also denote the step as difference instead of $\Delta$ when referring to the trajectory design. This provides additional clarity.}:

\begin{align}
d^{(j)} =  \frac{Y(\bold{b_{f \leq i}^{(j)}}, \bold{a_{h>i}^{(j)}}) - Y(\bold{b_{f<i}^{(j)}}, \bold{a_{h \geq i}^{(j)}})}{b_i^{(j)} - a_i^{(j)}} = \frac{Y(\bold{T_{i,*})} -  Y(\bold{T_{i-1,*}})}{b_i^{(j)} - a_i^{(j)}}.
\end{align}
The trajectory design involves first, a fixed grid, and second and more importantly, a fixed step $\Delta$. Hence the coverage of points is worse for larger samples. Additionally, $\{\Delta\} = \{\pm \Delta\}$ implies less variety vis-รก-vis the radial design.












\newpage
\bibliography{../../bibliography/literature}

\end{document}