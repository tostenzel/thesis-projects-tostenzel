\newpage

\section{Uncertainty Quantification Framework}
\thispagestyle{plain} % surpress header on first page

This section consists of three parts. The first part gives an overview of uncertainty quantification and introduces the basic notation. The following two parts explain the more involved UQ measures that are computed in this thesis.
The second part describes Morris screening. It is a method used to decrease the number of uncertain input parameters thereby reducing the computational burden for the following part.
The third part presents the Sobol' indices. These global measures attribute the variation in the quantity of interest to the uncertainty in individual input parameters. They constitute the thesis' main result.

\subsection{Overview of Uncertainty Quantification}
Model-based forecasting includes two main steps:\footnote{The general procedure of model-based forecasting can also include other steps. However, steps like model validation and model verification can also be viewed as belonging to the analysis of the so-called model uncertainty. The concept of model uncertainty is briefly explained in the next paragraph.} The first step is the calibration. In this step, the input parameters of the model are estimated. The second step is the prediction. The prediction contains the evaluation of model at the estimated parameters to make statements about the future. These statements are made in a probabilistic way. Thereby, the uncertainty of these statements is emphasised.\\
\newline
There are four sources of uncertainty in modern forecasts that are based on complex computational models. The first source, the model uncertainty, is the uncertainty of whether the mathematical model represents the reality appropriately.\footnote{However, It seems that there are not many powerful instruments to evaluate and improve the model uncertainty except comparing statements derived from the model to the data and then improving it where appropriate.} The second source, the input uncertainty, is the uncertainty about the size of the input parameters of the model. The third one, the numerical uncertainty, comes from potential errors and uncertainties introduced by the conversion from a mathematical to a computational model. The last source of uncertainty, the measurement uncertainty, is the accuracy of the experimental data that is used to approximate and calibrate the model.

The thesis deals with the second source of uncertainty, the input uncertainty. In my view, this is the source for which uncertainty quantification offers the most instruments and also the strongest instruments. This results from the fact that the estimation step yields basic measures for the variability or uncertainty in the input parameter estimates. These can then be used to compute a wide variety of measures for the input uncertainty.\\
\newline
The following explains the basic notation for the quantification of the input uncertainty. An essential step is to define the quantity that one wants to predict with a model. This quantity is called the quantity of interest (henceforth QoI) and denoted by $q$. For instance, the QoI in the thesis is the impact of a 500 USD tuition subsidy for higher education on average schooling years. The uncertain model parameters are denoted by vector $\pmb{\theta}$. The function that computes QoI $q$ by evaluating a computation model and, if necessary, post-processing the model output is denoted by $\mathcal{M}$. Thus,
\begin{align}
q = \mathcal{M}(\pmb{\theta}).
\end{align}
Large-scale UQ applications draw from various disciplines like probability, statistics, analysis, and numeric. They are used in a combined effort for parameter estimation, surrogate model construction, parameter selection, uncertainty propagation, LSA, and GSA, amongst others. 

Parameter estimation covers the calibration step. There is a large number of estimation techniques for various types of models. The thesis uses a maximum likelihood approach detailed in the Model and Estimation section. However, the parameter estimation is not the main focus. 


If the run time of a model is too long to compute some UQ measures, surrogate models are constructed to substitute the original model $\mathcal{M}$. These surrogate models are functions of the model input parameters that are faster to evaluate. They are also called interpolants because these functions are computed from a random sample of input parameter vectors drawn from the input distribution and evaluated by the model. Therefore, evaluations of the surrogate model interpolate this sample. Some techniques yield functions that have properties which simplify the computation of some UQ measures tremendously.

Another way to reduce computation, not necessarily of the model, but of UQ measures, is to reduce the number of uncertain input parameters as part of parameter selection. This is the approach that the thesis takes instead of the construction of a surrogate model.\footnote{Further remarks on the choice of measures and methods are discussed at the end of the literature review. This sequence allows for direct comparisons with other contributions.} The chosen technique is called Morris sampling and detailed in the following Global Sensitivity Analysis subsection.

Uncertainty propagation is the core of the prediction step. It comprises the construction of the QoI's probability distribution by propagating the input uncertainty through the model. For instance, this can be achieved by repeatedly evaluating a sample of random input parameters by the model (as also required for the construction of a surrogate model). Uncertainty propagation also involves the computation of descriptive statistics like the probabilities for a set of specific events in the QoI range using this distribution. This is conceptually simple. The results are presented in the Uncertainty Propagation section. The construction of the probability distribution is also important for designing the subsequent steps like a sensitivity analysis. For example, if the distribution is unimodal and symmetric variance-based UQ measures are meaningful. If the distribution has a less tractable, for instance a bimodal shape, density-based measures are better suited.

In UQ, sensitivity analysis has the objective of quantifying the relative contribution of the uncertainty in individual input parameters to the total uncertainty in the QoI. Moreover, it answers the question of how variations in parameters affect QoI responses. The thesis focuses on the first part because the range of the QoI's distribution has no particularly critical interval. If the results of a sensitivity analysis suggest that a parameter's contribution to the QoI's is negligible, this parameter can be fixed. These fixings simplify subsequent parameter estimations and uncertainty propagations. Therefore, these analyses can be applied alternately. Sensitivity analyses can be local or global.

Local sensitivity analysis is the most frequently used level of sensitivity analysis in the literature of most scientific disciplines. It provides measures for the above objectives by changes of input parameter values about some nominal values at specific choices of local points in the input parameter space. The two choices, the nominal value that changes the input parameters and the local point at which to change the parameters, contain a degree of arbitrariness. This arbitrariness can yield false results if the model is non-linear and does contain interactions between the input parameters. These limitations can be overcome in a global sensitivity analysis (henceforth GSA) as presented in the next subsection.\\
\newline
Beforehand, a vital remark is made in anticipation of the estimation results for the input parameters' uncertainty: In realistic models, the estimates for the input parameters tend to be correlated. Therefore, the measures and methods in the next section are presented with their respective extensions that allow for correlated input parameters. These extensions are published in contributions from the last 15 years. Therefore, they are relatively novel.

In general, the emphasis on UQ measures for models with correlated input parameters in the literature is not particularly strong.
This has the following reason: For correlated input parameters with a known, tractable joint distribution function like, for instance, the normal distribution, sampling-based measures can be computed by sampling from the unit cube. The samples are then converted from the unit cube to the domain of the joint probability distribution by evaluating the draws with the inverse cumulative distribution function, thereby accounting for the correlation. Alternatively, the decorrelation techniques Rosenblatt and Nataf transformation are usually used for less simple distribution functions



\subsection{Global Sensitivity Analysis}
\subsubsection{Morris Screening}
\cite{Morris.1991}

\cite{Saltelli.2008}

\cite{lemaire2013structural}
\cite{gentle2006random}
\cite{ge2017extending}
\subsubsection{Sobol' Indices}

\begin{align}
S_i = \frac{\text{Var}_i[Y|X_i ]}{\text{Var}[Y]}
\end{align}

\begin{align}
S_i = \frac{\text{Var}_i[\E_{\sim i}[Y|X_i ]]}{\text{Var}[Y]}
\end{align}

\begin{align}
S_{ij} = \frac{\text{Var}_{ij}[\E_{\sim \{i,j\}}[Y|X_i, X_j ]]}{\text{Var}[Y]} - S_i - S_j
\end{align}

\begin{align}
S_\text{u} = \frac{\text{Var}_\text{u}[\E_{\sim \text{u}}[Y|X_\text{u} ]]}{\text{Var}[Y]} - \sum_{\text{w} \subset \text{u}} S_\text{w}
\end{align}

\begin{align}
S_i^\text{T} = \sum_{i \in \text{u}} S_\text{u}
\end{align}

\begin{align}
\text{Var}[Y] = \text{Var}_i[\E_{\sim i}[Y|X_i]] + \E_{i}[\text{Var}_{\sim i}[Y|X_i]]
\end{align}

\begin{align}
1 = \frac{\text{Var}_i[\E_{\sim i}[Y|X_i]]}{\text{Var}[Y]} + \frac{\E_{i}[Var_{\sim i}[Y|X_i]]}{\text{Var}[Y]}
\end{align}
\begin{align}
1 = S_i + S_{\sim i}^T
\end{align}

\begin{align}
S_{\sim i}^T = \frac{\E_{i}[\text{Var}_{\sim i}[Y|X_i]]}{\text{Var}[Y]}
\end{align}

\begin{align}
S_{i}^T = \frac{\E_{\sim i}[\text{Var}_{i}[Y|X_{\sim i}]]}{\text{Var}[Y]}
\end{align}

\begin{align}
S_\text{u}^{clo} = \frac{\text{Var}_\text{u}[\E_{\sim \text{u}}[Y|X_\text{u} ]]}{\text{Var}[Y]}
\end{align}


\begin{align}
Y = \mathcal{M}(\text{x}) = \mathcal{M}_0 + \sum_{i=1}^{M} \mathcal{M}_i(x_i) + \sum_{1 \leq i \leq j \leq M} \mathcal{M}_{ij}(x_i,x_j) + ... + \mathcal{M}_{12..M}(\text{x})
\end{align}

\begin{align}
S_i = \frac{\text{Cov}[\mathcal{M}_i(x_i), Y]}{\text{Var}[Y]}
\end{align}

\begin{align}
S_i = \frac{\text{Var}[\mathcal{M}_i(x_i)]}{\text{Var}[Y]} + \frac{\text{Cov}[\mathcal{M}_i(x_i)]}{\text{Var}[Y]}
\end{align}

\begin{align}
S_i = \frac{\text{Var}_i[\mathcal{M}_i(x_i)]}{\text{Var}[Y]}
\end{align}

\begin{align}
S_{ij} = \frac{\text{Var}_{ij}[\mathcal{M}_{ij}(x_i,x_j)]}{\text{Var}[Y]}
\end{align}

\begin{align}
\text{Var}[Y] =  \sum_{i=1}^{M} \text{Var}[\mathcal{M}_i(x_i)] + \sum_{1 \leq i \leq j \leq M} \text{Var}[\mathcal{M}_{ij}(x_i,x_j)] + ... + \text{Var}[\mathcal{M}_{12..M}(\text{x})]
\end{align}

\begin{equation}
\begin{aligned}
S_i^T = S_i + \sum_{j \ne i} S_{ij} + \sum_{1 \leq i \leq j \leq M,\{j,k\} \ne i} S_{ijk} + ... = \sum_{i \in \text{w}} S_\text{w} = \\
\frac{1}{\text{Var}[Y]}\sum_{i \in \text{w}} \text{Var}_i[\mathcal{M}_\text{w}(x_\text{w})]
\end{aligned}
\end{equation}

\begin{align}
S_\text{u}^{clo} = \frac{\text{Var}_\text{u}[\mathcal{M}_\text{u}(\text{x}_\text{u})]}{\text{Var}[Y]} +  \sum_{\text{w} \subseteq \text{u}} \frac{\text{Var}_\text{w}[\mathcal{M}_\text{w}(\text{x}_\text{w})]}{\text{Var}[Y]}
\end{align}


\subsection{Surrogate Models and Spectral Expansions}


[Univariate Effects as a measure for comparative statics]

[Philipp: Please add a plot to your thesis (not our notebook) that implements the idea of the uncertainty cone in Figure 1. 2 in our textbook. For example, Figure 1 from KW97 could use such a cone for hte out of support predictions in the occupational shares.]

\newpage
%exlude, just to see how large the next chapter is